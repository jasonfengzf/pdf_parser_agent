import os
import json
import requests
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum

# LangChain imports
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# Vector store imports
from pymilvus import connections, Collection, utility

from config import DEEPSEEK_API_KEY


class AgentType(Enum):
    """æ™ºèƒ½ä½“ç±»å‹æšä¸¾"""
    KNOWLEDGE_RETRIEVER = "knowledge_retriever"  # çŸ¥è¯†åº“æ£€ç´¢æ™ºèƒ½ä½“
    DOMAIN_ADVISOR = "domain_advisor"  # é¢†åŸŸé¡¾é—®æ™ºèƒ½ä½“
    LEARNING_CONSULTANT = "learning_consultant"  # å­¦ä¹ é¡¾é—®æ™ºèƒ½ä½“


@dataclass
class SearchResult:
    """ç»Ÿä¸€æœç´¢ç»“æœæ•°æ®ç»“æ„"""
    rank: int
    score: float
    content: str
    metadata: Dict
    source_type: str


class VectorStoreManager:
    """çŸ¥è¯†åº“æ£€ç´¢ç®¡ç†å™¨ - é€‚é…Milvuså‘é‡åº“"""

    def __init__(self, host='localhost', port='19530', api_key=None):
        self.host = host
        self.port = port
        self.api_key = api_key or os.getenv('QWEN_API_KEY')
        self.base_url = 'https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings'

        # å‘é‡åº“é›†åˆé…ç½®
        self.collections = {
            'paper_contents': 'paper_contents',  # è®ºæ–‡å†…å®¹
            'paper_figures': 'paper_figures',  # è®ºæ–‡å›¾ç‰‡
            'file_contents': 'file_contents'  # æ–‡ä»¶å†…å®¹
        }

        self._connect_milvus()

    def _connect_milvus(self):
        """è¿æ¥Milvusæ•°æ®åº“"""
        try:
            connections.connect(host=self.host, port=self.port)
            print("âœ… MilvusçŸ¥è¯†åº“è¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Milvusè¿æ¥å¤±è´¥: {e}")

    def get_embedding(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬å‘é‡"""
        headers = {'Authorization': f'Bearer {self.api_key}', 'Content-Type': 'application/json'}
        data = {"model": "text-embedding-v1", "input": text[:2000]}

        try:
            response = requests.post(self.base_url, headers=headers, json=data, timeout=30)
            result = response.json()

            if 'data' in result and result['data']:
                return result['data'][0]['embedding']
            else:
                import random
                return [random.uniform(-1, 1) for _ in range(1536)]

        except Exception as e:
            print(f"è·å–å‘é‡å¤±è´¥: {e}")
            import random
            return [random.uniform(-1, 1) for _ in range(1536)]

    def search_papers(self, query: str, top_k: int = 10) -> List[SearchResult]:
        """è®ºæ–‡æ£€ç´¢"""
        return self._search_collection(
            self.collections['paper_contents'], query, top_k,
            ["file_name", "directory", "content_type", "text_content",
             "text_level", "page_idx", "text_format", "image_caption"]
        )

    def search_content(self, query: str, top_k: int = 8) -> List[SearchResult]:
        """è®ºæ–‡å†…å®¹æ£€ç´¢"""
        results = self._search_collection(
            self.collections['paper_contents'], query, top_k,
            ["file_name", "directory", "content_type", "text_content",
             "text_level", "page_idx", "text_format"]
        )
        return [r for r in results if r.metadata.get('content_type') == 'text']

    def search_figures(self, query: str, top_k: int = 6) -> List[SearchResult]:
        """è®ºæ–‡å›¾ç‰‡æ£€ç´¢"""
        return self._search_collection(
            self.collections['paper_figures'], query, top_k,
            ["file_name", "figure_id", "figure_name", "section",
             "conclusion", "subfigure_count", "subfigure_data", "content"]
        )

    def _search_collection(self, collection_name: str, query: str, top_k: int,
                           output_fields: List[str]) -> List[SearchResult]:
        """é€šç”¨å‘é‡æœç´¢æ–¹æ³•"""
        if not utility.has_collection(collection_name):
            print(f"âŒ é›†åˆ {collection_name} ä¸å­˜åœ¨")
            return []

        collection = Collection(collection_name)
        collection.load()

        query_vector = self.get_embedding(query)
        search_params = {"metric_type": "L2", "params": {"nprobe": 10}}

        try:
            results = collection.search(
                data=[query_vector],
                anns_field="vector",
                param=search_params,
                limit=top_k,
                output_fields=output_fields
            )

            formatted_results = []
            for i, hit in enumerate(results[0]):
                result = SearchResult(
                    rank=i + 1,
                    score=1 - float(hit.distance),
                    content=self._extract_content(hit.entity, collection_name),
                    metadata={field: hit.entity.get(field) for field in output_fields},
                    source_type=collection_name
                )
                formatted_results.append(result)

            return formatted_results
        except Exception as e:
            print(f"æœç´¢å¤±è´¥: {e}")
            return []

    def _extract_content(self, entity, collection_name: str) -> str:
        """æ ¹æ®é›†åˆç±»å‹æå–ä¸»è¦å†…å®¹"""
        if collection_name == self.collections['paper_contents']:
            return entity.get('text_content', '')
        elif collection_name == self.collections['paper_figures']:
            figure_name = entity.get('figure_name', '')
            conclusion = entity.get('conclusion', '')
            return f"{figure_name}: {conclusion}"
        elif collection_name == self.collections['file_contents']:
            return entity.get('content', '')
        return ""


class LLMService:
    """ç»Ÿä¸€çš„LLMæœåŠ¡"""

    def __init__(self):
        self.llm = ChatOpenAI(
            model="deepseek-chat",
            openai_api_base="https://api.deepseek.com/v1",
            openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
            temperature=0.7
        )

    def generate_response(self, prompt: str, system_prompt: str = "") -> str:
        """ç”Ÿæˆå›å¤"""
        messages = []
        if system_prompt:
            messages.append(SystemMessage(content=system_prompt))
        messages.append(HumanMessage(content=prompt))

        try:
            response = self.llm.invoke(messages)
            return response.content
        except Exception as e:
            return f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}"


class BaseAgent:
    """æ™ºèƒ½ä½“åŸºç±»"""

    def __init__(self):
        self.llm = LLMService()
        self.vector_store = VectorStoreManager()


class KnowledgeRetrieverAgent(BaseAgent):
    """çŸ¥è¯†åº“æ£€ç´¢æ™ºèƒ½ä½“ - è´Ÿè´£æ‰€æœ‰æ£€ç´¢åŠŸèƒ½"""

    def retrieve_information(self, query: str, search_type: str = "all") -> str:
        """ç»¼åˆæ£€ç´¢ä¿¡æ¯"""
        print(f"ğŸ” çŸ¥è¯†åº“æ£€ç´¢: {query} - ç±»å‹: {search_type}")

        if search_type == "papers" or search_type == "all":
            papers = self.vector_store.search_papers(query, top_k=8)
        else:
            papers = []

        if search_type == "content" or search_type == "all":
            contents = self.vector_store.search_content(query, top_k=6)
        else:
            contents = []

        if search_type == "figures" or search_type == "all":
            figures = self.vector_store.search_figures(query, top_k=5)
        else:
            figures = []

        prompt = f"""
        # çŸ¥è¯†åº“æ£€ç´¢æŠ¥å‘Š

        ## æ£€ç´¢æŸ¥è¯¢
        {query}

        ## æ£€ç´¢ç±»å‹
        {search_type}

        ## æ£€ç´¢ç»“æœ

        ### ğŸ“š ç›¸å…³è®ºæ–‡ ({len(papers)}ç¯‡)
        {self._format_paper_results(papers)}

        ### ğŸ“– ç›¸å…³å†…å®¹ ({len(contents)}æ¡)
        {self._format_content_results(contents)}

        ### ğŸ–¼ï¸ ç›¸å…³å›¾è¡¨ ({len(figures)}ä¸ª)
        {self._format_figure_results(figures)}

        è¯·åŸºäºä»¥ä¸Šæ£€ç´¢ç»“æœï¼š
        1. æ€»ç»“æ£€ç´¢åˆ°çš„ä¸»è¦ä¿¡æ¯
        2. åˆ†æä¿¡æ¯çš„ç›¸å…³æ€§å’Œå®Œæ•´æ€§
        3. æä¾›è¿›ä¸€æ­¥æ£€ç´¢çš„å»ºè®®

        è¦æ±‚ï¼šå…¨é¢å®¢è§‚ï¼Œé‡ç‚¹çªå‡ºæ£€ç´¢ç»“æœã€‚
        """

        system_prompt = "ä½ æ˜¯çŸ¥è¯†åº“æ£€ç´¢ä¸“å®¶ï¼Œæ“…é•¿ä»å‘é‡æ•°æ®åº“ä¸­é«˜æ•ˆæ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚"
        return self.llm.generate_response(prompt, system_prompt)

    def _format_paper_results(self, papers: List[SearchResult]) -> str:
        """æ ¼å¼åŒ–è®ºæ–‡ç»“æœ"""
        if not papers:
            return "æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡"

        formatted = ""
        file_groups = {}
        for paper in papers:
            filename = paper.metadata.get('file_name', 'æœªçŸ¥æ–‡ä»¶')
            if filename not in file_groups:
                file_groups[filename] = []
            file_groups[filename].append(paper)

        for filename, papers_in_file in list(file_groups.items())[:5]:
            formatted += f"**{filename}**\n"
            for paper in papers_in_file[:2]:
                content_preview = paper.content[:150] + "..." if len(paper.content) > 150 else paper.content
                formatted += f"- {content_preview} (ç›¸å…³åº¦: {paper.score:.3f})\n"
            formatted += "\n"

        return formatted

    def _format_content_results(self, contents: List[SearchResult]) -> str:
        """æ ¼å¼åŒ–å†…å®¹ç»“æœ"""
        if not contents:
            return "æœªæ‰¾åˆ°ç›¸å…³å†…å®¹"

        formatted = ""
        for content in contents[:5]:
            filename = content.metadata.get('file_name', 'æœªçŸ¥æ–‡ä»¶')
            page = content.metadata.get('page_idx', 0) + 1
            text = content.content[:200] + "..." if len(content.content) > 200 else content.content
            formatted += f"**{filename}** (ç¬¬{page}é¡µ, ç›¸å…³åº¦: {content.score:.3f})\n"
            formatted += f"{text}\n\n"

        return formatted

    def _format_figure_results(self, figures: List[SearchResult]) -> str:
        """æ ¼å¼åŒ–å›¾è¡¨ç»“æœ"""
        if not figures:
            return "æœªæ‰¾åˆ°ç›¸å…³å›¾è¡¨"

        formatted = ""
        for figure in figures:
            name = figure.metadata.get('figure_name', 'æœªçŸ¥å›¾è¡¨')
            conclusion = figure.metadata.get('conclusion', '')
            section = figure.metadata.get('section', '')

            formatted += f"### {name}\n"
            if section:
                formatted += f"**ç« èŠ‚**: {section}\n"
            formatted += f"**ç»“è®º**: {conclusion}\n"
            formatted += f"**ç›¸å…³åº¦**: {figure.score:.3f}\n\n"

        return formatted


class DomainAdvisorAgent(BaseAgent):
    """é¢†åŸŸé¡¾é—®æ™ºèƒ½ä½“ - è´Ÿè´£ä¸“ä¸šåˆ†æå’Œå»ºè®®"""

    def provide_expert_advice(self, query: str, advice_type: str = "comprehensive") -> str:
        """æä¾›ä¸“ä¸šé¢†åŸŸå»ºè®®"""
        print(f"ğŸ“ é¢†åŸŸå»ºè®®: {query} - ç±»å‹: {advice_type}")

        # æœç´¢ç›¸å…³åŸºç¡€ä¿¡æ¯
        papers = self.vector_store.search_papers(query, top_k=6)
        contents = self.vector_store.search_content(query, top_k=4)
        figures = self.vector_store.search_figures(query, top_k=3)

        prompt = f"""
        # ææ–™ç§‘å­¦é¢†åŸŸä¸“å®¶å»ºè®®

        ## å’¨è¯¢é—®é¢˜
        {query}

        ## å’¨è¯¢ç±»å‹
        {advice_type}

        ## ç›¸å…³ç ”ç©¶åŸºç¡€
        {self._format_expert_content(papers, contents, figures)}

        {self._get_analysis_framework(advice_type)}

        è¦æ±‚ï¼šåˆ†æä¸“ä¸šæ·±å…¥ï¼Œå»ºè®®å…·ä½“å¯è¡Œï¼ŒåŸºäºç§‘å­¦åŸç†ã€‚
        """

        system_prompt = """ä½ æ˜¯èµ„æ·±çš„ææ–™ç§‘å­¦é¢†åŸŸä¸“å®¶ï¼Œåœ¨é‡‘å±ææ–™ã€ç›¸å˜è¡Œä¸ºã€æ™¶ä½“ç»“æ„ç­‰æ–¹é¢æœ‰æ·±åšé€ è¯£ã€‚
        ä½ çš„åˆ†æåº”è¯¥åŸºäºç§‘å­¦åŸç†ï¼Œå»ºè®®åº”è¯¥å…·ä½“å¯è¡Œã€‚"""

        return self.llm.generate_response(prompt, system_prompt)

    def _get_analysis_framework(self, advice_type: str) -> str:
        """æ ¹æ®å»ºè®®ç±»å‹è·å–åˆ†ææ¡†æ¶"""
        frameworks = {
            "comprehensive": """
            è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œå…¨é¢åˆ†æï¼š

            ### ğŸ¯ æ ¸å¿ƒå†…å®¹æç‚¼
            - ä¸»è¦ç§‘å­¦é—®é¢˜å’Œç ”ç©¶æ–¹æ³•
            - å…³é”®å®éªŒå‘ç°å’ŒæŠ€æœ¯åˆ›æ–°
            - é‡è¦ç†è®ºè´¡çŒ®

            ### ğŸ’ ç ”ç©¶ä»·å€¼è¯„ä¼°
            - ç†è®ºåˆ›æ–°æ€§å’Œç§‘å­¦æ„ä¹‰
            - æŠ€æœ¯çªç ´å’Œåº”ç”¨å‰æ™¯
            - å¯¹é¢†åŸŸå‘å±•çš„å½±å“

            ### ğŸ”¬ ä¸“ä¸šæ¦‚å¿µè§£æ
            - ç›¸å…³ä¸“ä¸šæ¦‚å¿µçš„å‡†ç¡®è§£é‡Š
            - ç‰©ç†/åŒ–å­¦æœºåˆ¶åˆ†æ
            - åœ¨ææ–™ç§‘å­¦ä¸­çš„å…·ä½“è¡¨ç°

            ### ğŸ“Š å®éªŒæ•°æ®è§£è¯»
            - å…³é”®æ•°æ®çš„ç§‘å­¦å«ä¹‰
            - å®éªŒç»“æœçš„å¯é æ€§åˆ†æ
            - æ•°æ®è¶‹åŠ¿çš„ç‰©ç†æ„ä¹‰

            ### ğŸ› ï¸ æ–¹æ³•æŠ€æœ¯æŒ‡å¯¼
            - å®éªŒè®¾è®¡å’ŒæŠ€æœ¯è·¯çº¿
            - æ“ä½œè¦ç‚¹å’Œæ³¨æ„äº‹é¡¹
            - æ›¿ä»£æ–¹æ¡ˆæ¯”è¾ƒ

            ### âš–ï¸ æ€§èƒ½ç³»ç»Ÿæ¯”è¾ƒ
            - å…³é”®æ€§èƒ½å‚æ•°å¯¹æ¯”
            - ä¼˜ç¼ºç‚¹åˆ†æ
            - é€‚ç”¨åœºæ™¯è¯„ä¼°

            ### ğŸš€ ä¼˜åŒ–å‘å±•å»ºè®®
            - ç ”ç©¶æ–¹å‘å»ºè®®
            - æŠ€æœ¯æ”¹è¿›æ–¹æ¡ˆ
            - åˆ›æ–°æœºä¼šè¯†åˆ«
            """,

            "research": """
            è¯·é‡ç‚¹è¿›è¡Œç ”ç©¶æ–¹å‘åˆ†æï¼š

            ### ğŸ” ç ”ç©¶ç°çŠ¶åˆ†æ
            - å½“å‰ç ”ç©¶æ°´å¹³å’Œè¿›å±•
            - ä¸»è¦æŠ€æœ¯è·¯çº¿å’Œæ–¹æ³•
            - å­˜åœ¨çš„ç§‘å­¦é—®é¢˜

            ### ğŸ¯ ç ”ç©¶æ–¹å‘å»ºè®®
            - æ½œåœ¨çš„çªç ´æ–¹å‘
            - äº¤å‰å­¦ç§‘æœºä¼š
            - å‰æ²¿çƒ­ç‚¹è¿½è¸ª

            ### ğŸ’¡ ä¼˜åŒ–æ”¹è¿›å»ºè®®
            - å®éªŒè®¾è®¡ä¼˜åŒ–
            - æ•°æ®åˆ†ææ–¹æ³•æ”¹è¿›
            - ç†è®ºæ¨¡å‹å®Œå–„
            """,

            "concept": """
            è¯·é‡ç‚¹è¿›è¡Œæ¦‚å¿µè§£æï¼š

            ### ğŸ“– æ¦‚å¿µå®šä¹‰é˜è¿°
            - å‡†ç¡®çš„å®šä¹‰å’Œå†…æ¶µ
            - ç›¸å…³æœ¯è¯­è¯´æ˜
            - å†å²å‘å±•è„‰ç»œ

            ### ğŸ¯ ç§‘å­¦åŸç†åˆ†æ
            - ç‰©ç†/åŒ–å­¦æœºåˆ¶
            - ç†è®ºåŸºç¡€å’Œæ¨¡å‹
            - å…³é”®å‚æ•°å’Œç‰¹å¾

            ### ğŸ’¡ åº”ç”¨æ„ä¹‰è¯´æ˜
            - åœ¨ææ–™ç§‘å­¦ä¸­çš„é‡è¦æ€§
            - å®é™…åº”ç”¨åœºæ™¯
            - ç ”ç©¶ä»·å€¼è¯„ä¼°
            """,

            "method": """
            è¯·é‡ç‚¹è¿›è¡Œæ–¹æ³•æŒ‡å¯¼ï¼š

            ### ğŸ› ï¸ æŠ€æœ¯è·¯çº¿è®¾è®¡
            - å®éªŒæµç¨‹è§„åˆ’
            - å…³é”®æŠ€æœ¯é€‰æ‹©
            - è´¨é‡æ§åˆ¶æªæ–½

            ### âš™ï¸ æ“ä½œå®æ–½æŒ‡å—
            - å…·ä½“æ“ä½œæ­¥éª¤
            - ä»ªå™¨è®¾å¤‡è¦æ±‚
            - å‚æ•°è®¾ç½®å»ºè®®

            ### ğŸ“Š æ•°æ®åˆ†ææ–¹æ³•
            - æ•°æ®å¤„ç†æµç¨‹
            - ç»Ÿè®¡åˆ†ææ–¹æ³•
            - ç»“æœéªŒè¯æ–¹æ¡ˆ
            """
        }

        return frameworks.get(advice_type, frameworks["comprehensive"])

    def _format_expert_content(self, papers: List[SearchResult], contents: List[SearchResult],
                               figures: List[SearchResult]) -> str:
        """æ ¼å¼åŒ–ä¸“å®¶åˆ†æå†…å®¹"""
        formatted = "### ç›¸å…³ç ”ç©¶å†…å®¹\n\n"

        if papers:
            formatted += "#### è®ºæ–‡ç ”ç©¶æˆæœ\n"
            for paper in papers[:4]:
                content_preview = paper.content[:250] + "..." if len(paper.content) > 250 else paper.content
                formatted += f"- {content_preview} (ç›¸å…³åº¦: {paper.score:.3f})\n"
            formatted += "\n"

        if contents:
            formatted += "#### å…·ä½“å†…å®¹åˆ†æ\n"
            for content in contents[:3]:
                formatted += f"- {content.content[:200]}...\n"
            formatted += "\n"

        if figures:
            formatted += "#### å®éªŒæ•°æ®æ”¯æ’‘\n"
            for figure in figures[:2]:
                name = figure.metadata.get('figure_name', 'æœªçŸ¥å›¾è¡¨')
                conclusion = figure.metadata.get('conclusion', '')[:150] + "..." if len(
                    figure.metadata.get('conclusion', '')) > 150 else figure.metadata.get('conclusion', '')
                formatted += f"- {name}: {conclusion} (ç›¸å…³åº¦: {figure.score:.3f})\n"

        return formatted


class LearningConsultantAgent(BaseAgent):
    """å­¦ä¹ é¡¾é—®æ™ºèƒ½ä½“ - è´Ÿè´£å­¦ä¹ å»ºè®®å’Œèµ„æ–™æ¨è"""

    def provide_learning_guidance(self, user_input: str) -> str:
        """æä¾›å­¦ä¹ æŒ‡å¯¼å’Œå»ºè®®"""
        print(f"ğŸ“ å­¦ä¹ æŒ‡å¯¼: {user_input}")

        # æœç´¢ç›¸å…³çŸ¥è¯†å†…å®¹ç”¨äºåˆ†æåŸºç¡€
        papers = self.vector_store.search_papers(user_input, top_k=4)
        contents = self.vector_store.search_content(user_input, top_k=3)

        prompt = f"""
        # ä¸ªæ€§åŒ–å­¦ä¹ æŒ‡å¯¼æ–¹æ¡ˆ

        ## å­¦ä¹ éœ€æ±‚åˆ†æ
        {user_input}

        ## ç°æœ‰çŸ¥è¯†åŸºç¡€
        {self._format_learning_base(papers, contents)}

        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œæä¾›å…¨é¢çš„å­¦ä¹ æŒ‡å¯¼ï¼š

        ### ğŸ” çŸ¥è¯†ç›²ç‚¹è¯Šæ–­
        - å¯èƒ½å­˜åœ¨çš„ç†è§£è¯¯åŒºåˆ†æ
        - åŸºç¡€æ¦‚å¿µçš„æŒæ¡ç¨‹åº¦è¯„ä¼°
        - æŠ€æœ¯ç»†èŠ‚çš„è®¤çŸ¥å·®è·è¯†åˆ«

        ### ğŸŒ æœ€ä¼˜å­¦ä¹ èµ„æ–™æ¨è

        #### ç½‘ç»œå­¦ä¹ èµ„æº
        - ä¼˜è´¨åœ¨çº¿è¯¾ç¨‹å’ŒMOOCå¹³å°æ¨è
        - ä¸“ä¸šå­¦ä¹ ç½‘ç«™å’Œæ•°æ®åº“
        - æœ€æ–°ç ”ç©¶åŠ¨æ€å’Œå­¦æœ¯èµ„è®¯æ¥æº

        #### ç»å…¸å­¦æœ¯æ–‡çŒ®
        - å¿…è¯»çš„åŸºç¡€ç†è®ºæ•™ç§‘ä¹¦
        - é‡è¦çš„ç»¼è¿°æ€§è®ºæ–‡
        - å‰æ²¿ç ”ç©¶çªç ´æ€§æ–‡ç« 

        #### å®è·µå­¦ä¹ ææ–™
        - å®éªŒæ“ä½œæ‰‹å†Œå’ŒæŒ‡å—
        - ä»¿çœŸæ¨¡æ‹Ÿå·¥å…·å’Œæ•™ç¨‹
        - æ•°æ®åˆ†æè½¯ä»¶å’Œå­¦ä¹ èµ„æº

        ### ğŸ—ºï¸ ç³»ç»Ÿå­¦ä¹ è·¯å¾„

        #### åˆçº§é˜¶æ®µ
        - åŸºç¡€ç†è®ºçŸ¥è¯†å­¦ä¹ 
        - æ ¸å¿ƒæ¦‚å¿µç†è§£
        - åŸºæœ¬æŠ€èƒ½åŸ¹å…»

        #### è¿›é˜¶é˜¶æ®µ  
        - ä¸“ä¸šæ·±åº¦çŸ¥è¯†å­¦ä¹ 
        - ç ”ç©¶æ–¹æ³•æŒæ¡
        - å®è·µèƒ½åŠ›æå‡

        #### é«˜çº§é˜¶æ®µ
        - å‰æ²¿æŠ€æœ¯å­¦ä¹ 
        - åˆ›æ–°èƒ½åŠ›åŸ¹å…»
        - å­¦æœ¯äº¤æµå‚ä¸

        ### ğŸ’¡ é«˜æ•ˆå­¦ä¹ ç­–ç•¥
        - ä¸ªæ€§åŒ–å­¦ä¹ æ–¹æ³•å»ºè®®
        - çŸ¥è¯†å·©å›ºå’Œå®è·µæŠ€å·§
        - å­¦ä¹ è¿›åº¦ç®¡ç†å’Œè¯„ä¼°

        ### ğŸ¯ å­¦ä¹ ç›®æ ‡è®¾å®š
        - çŸ­æœŸç›®æ ‡ï¼ˆ1-3ä¸ªæœˆï¼‰
        - ä¸­æœŸç›®æ ‡ï¼ˆ6-12ä¸ªæœˆï¼‰ 
        - é•¿æœŸç›®æ ‡ï¼ˆ1-2å¹´ï¼‰

        è¦æ±‚ï¼šåˆ†æå‡†ç¡®æ·±å…¥ï¼Œæ¨èå…·ä½“å®ç”¨ï¼Œè·¯å¾„æ¸…æ™°å¯è¡Œã€‚
        """

        system_prompt = """ä½ æ˜¯ä¸“ä¸šçš„å­¦æœ¯å¯¼å¸ˆå’Œå­¦ä¹ é¡¾é—®ï¼Œæ“…é•¿åˆ†æå­¦ç”Ÿçš„å­¦ä¹ éœ€æ±‚å¹¶æä¾›æœ€ä¼˜çš„å­¦ä¹ æ–¹æ¡ˆã€‚
        ä½ çš„å»ºè®®åº”è¯¥åŸºäºæœ€æ–°çš„æ•™è‚²èµ„æºå’Œå­¦ä¹ æ–¹æ³•ï¼Œæä¾›ä¸ªæ€§åŒ–çš„æˆé•¿è·¯å¾„ã€‚"""

        return self.llm.generate_response(prompt, system_prompt)

    def _format_learning_base(self, papers: List[SearchResult], contents: List[SearchResult]) -> str:
        """æ ¼å¼åŒ–å­¦ä¹ åŸºç¡€å†…å®¹"""
        formatted = "### ç›¸å…³çŸ¥è¯†å†…å®¹æ¦‚è§ˆ\n\n"

        if papers or contents:
            all_contents = list(papers) + list(contents)
            all_contents.sort(key=lambda x: x.score, reverse=True)

            for item in all_contents[:5]:
                content_preview = item.content[:180] + "..." if len(item.content) > 180 else item.content
                formatted += f"- {content_preview} (ç›¸å…³åº¦: {item.score:.3f})\n"
        else:
            formatted += "å½“å‰çŸ¥è¯†åº“ä¸­ç›¸å…³å†…å®¹æœ‰é™ï¼Œå°†ä¸»è¦åŸºäºé€šç”¨å­¦ä¹ ç†è®ºæä¾›å»ºè®®\n"

        formatted += "\n### ğŸ’¡ æç¤ºï¼šå­¦ä¹ å»ºè®®å°†ç»“åˆæœ€æ–°ç½‘ç»œèµ„æºå’Œå­¦æœ¯åŠ¨æ€"

        return formatted


class MaterialScienceQASystem:
    """ææ–™ç§‘å­¦é—®ç­”ç³»ç»Ÿ - ä¸‰å¤§æ ¸å¿ƒæ™ºèƒ½ä½“"""

    def __init__(self):
        # åˆå§‹åŒ–ä¸‰å¤§æ ¸å¿ƒæ™ºèƒ½ä½“
        self.agents = {
            AgentType.KNOWLEDGE_RETRIEVER: KnowledgeRetrieverAgent(),
            AgentType.DOMAIN_ADVISOR: DomainAdvisorAgent(),
            AgentType.LEARNING_CONSULTANT: LearningConsultantAgent(),
        }

        # æ™ºèƒ½ä½“è·¯ç”±é…ç½®
        self.agent_routing = {
            AgentType.KNOWLEDGE_RETRIEVER: [
                'æ£€ç´¢', 'æœç´¢', 'æŸ¥æ‰¾', 'è®ºæ–‡æ£€ç´¢', 'å†…å®¹æ£€ç´¢', 'å›¾ç‰‡æ£€ç´¢',
                'retrieve', 'search', 'find', 'paper search', 'content search'
            ],
            AgentType.DOMAIN_ADVISOR: [
                'åˆ†æ', 'è¯„ä¼°', 'å»ºè®®', 'è§£é‡Š', 'æŒ‡å¯¼', 'æ¯”è¾ƒ', 'ç ”ç©¶æ–¹å‘',
                'analyze', 'evaluate', 'advice', 'explain', 'guidance', 'comparison'
            ],
            AgentType.LEARNING_CONSULTANT: [
                'å­¦ä¹ ', 'èµ„æ–™', 'ç›²ç‚¹', 'è·¯å¾„', 'å»ºè®®', 'å¦‚ä½•å­¦ä¹ ', 'å­¦ä¹ è®¡åˆ’',
                'learn', 'study', 'materials', 'blind spot', 'learning path'
            ]
        }

    def route_query(self, query: str) -> Tuple[AgentType, float]:
        """è·¯ç”±æŸ¥è¯¢åˆ°åˆé€‚çš„æ™ºèƒ½ä½“"""
        query_lower = query.lower()

        agent_scores = {}
        for agent_type, keywords in self.agent_routing.items():
            score = sum(1 for keyword in keywords if keyword in query_lower)
            agent_scores[agent_type] = score

        best_agent = max(agent_scores, key=agent_scores.get)
        confidence = agent_scores[best_agent] / max(len(self.agent_routing[best_agent]), 1)

        return best_agent, confidence

    def process_query(self, query: str) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        agent_type, confidence = self.route_query(query)
        print(f"ğŸ¤– åˆ†é…æ™ºèƒ½ä½“: {agent_type.value} (ç½®ä¿¡åº¦: {confidence:.2f})")

        agent = self.agents[agent_type]

        try:
            if agent_type == AgentType.KNOWLEDGE_RETRIEVER:
                # æ ¹æ®æŸ¥è¯¢å†…å®¹ç¡®å®šæ£€ç´¢ç±»å‹
                if 'è®ºæ–‡' in query or 'æ–‡çŒ®' in query:
                    search_type = "papers"
                elif 'å†…å®¹' in query or 'æ–‡æœ¬' in query:
                    search_type = "content"
                elif 'å›¾ç‰‡' in query or 'å›¾è¡¨' in query or 'å›¾' in query:
                    search_type = "figures"
                else:
                    search_type = "all"
                return agent.retrieve_information(query, search_type)

            elif agent_type == AgentType.DOMAIN_ADVISOR:
                # æ ¹æ®æŸ¥è¯¢å†…å®¹ç¡®å®šå»ºè®®ç±»å‹
                if 'æ¦‚å¿µ' in query or 'è§£é‡Š' in query or 'æ˜¯ä»€ä¹ˆ' in query:
                    advice_type = "concept"
                elif 'æ–¹æ³•' in query or 'æŠ€æœ¯' in query or 'å®éªŒ' in query:
                    advice_type = "method"
                elif 'ç ”ç©¶' in query or 'æ–¹å‘' in query or 'ä¼˜åŒ–' in query:
                    advice_type = "research"
                else:
                    advice_type = "comprehensive"
                return agent.provide_expert_advice(query, advice_type)

            elif agent_type == AgentType.LEARNING_CONSULTANT:
                return agent.provide_learning_guidance(query)

            else:
                return "æš‚ä¸æ”¯æŒè¯¥ç±»å‹æŸ¥è¯¢"

        except Exception as e:
            return f"âŒ å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}"


def run_three_agents_tests():
    """è¿è¡Œä¸‰å¤§æ™ºèƒ½ä½“æµ‹è¯•"""
    print("ğŸ”¬ ææ–™ç§‘å­¦æ™ºèƒ½é—®ç­”ç³»ç»Ÿ - ä¸‰å¤§æ™ºèƒ½ä½“æµ‹è¯•")
    print("=" * 60)

    # è®¾ç½®APIå¯†é’¥
    if not os.getenv("DEEPSEEK_API_KEY"):
        os.environ["DEEPSEEK_API_KEY"] = DEEPSEEK_API_KEY

    qa_system = MaterialScienceQASystem()

    # ä¸‰å¤§æ™ºèƒ½ä½“æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        # çŸ¥è¯†åº“æ£€ç´¢æ™ºèƒ½ä½“æµ‹è¯•
        {
            "query": "æ£€ç´¢å…³äºé‡‘å±ç»ç’ƒå½¢æˆèƒ½åŠ›çš„ç›¸å…³è®ºæ–‡",
            "expected_agent": AgentType.KNOWLEDGE_RETRIEVER,
            "description": "æµ‹è¯•è®ºæ–‡æ£€ç´¢åŠŸèƒ½"
        },
        {
            "query": "æœç´¢Taå’ŒZrç»“æ™¶åŠ¨åŠ›å­¦å·®å¼‚çš„å…·ä½“å†…å®¹",
            "expected_agent": AgentType.KNOWLEDGE_RETRIEVER,
            "description": "æµ‹è¯•å†…å®¹æ£€ç´¢åŠŸèƒ½"
        },
        {
            "query": "æŸ¥æ‰¾EAMåŠ¿å‡½æ•°æ¯”è¾ƒçš„å›¾è¡¨",
            "expected_agent": AgentType.KNOWLEDGE_RETRIEVER,
            "description": "æµ‹è¯•å›¾ç‰‡æ£€ç´¢åŠŸèƒ½"
        },

        # é¢†åŸŸé¡¾é—®æ™ºèƒ½ä½“æµ‹è¯•
        {
            "query": "åˆ†æèƒ¡è¿œè¶…è€å¸ˆè®ºæ–‡çš„æ ¸å¿ƒå†…å®¹å’Œç ”ç©¶ä»·å€¼",
            "expected_agent": AgentType.DOMAIN_ADVISOR,
            "description": "æµ‹è¯•ç ”ç©¶åˆ†æåŠŸèƒ½"
        },
        {
            "query": "è§£é‡Šä»€ä¹ˆæ˜¯å‡†æ™¶ç›¸åŠå…¶åœ¨é‡‘å±ç»ç’ƒä¸­çš„ä½œç”¨",
            "expected_agent": AgentType.DOMAIN_ADVISOR,
            "description": "æµ‹è¯•æ¦‚å¿µè§£é‡ŠåŠŸèƒ½"
        },
        {
            "query": "æŒ‡å¯¼å¦‚ä½•ç”¨åˆ†å­åŠ¨åŠ›å­¦ç ”ç©¶é‡‘å±ç›¸å˜",
            "expected_agent": AgentType.DOMAIN_ADVISOR,
            "description": "æµ‹è¯•æ–¹æ³•æŒ‡å¯¼åŠŸèƒ½"
        },
        {
            "query": "æ¯”è¾ƒTaå’ŒZrçš„ç»ç’ƒå½¢æˆèƒ½åŠ›",
            "expected_agent": AgentType.DOMAIN_ADVISOR,
            "description": "æµ‹è¯•æ€§èƒ½æ¯”è¾ƒåŠŸèƒ½"
        },

        # å­¦ä¹ é¡¾é—®æ™ºèƒ½ä½“æµ‹è¯•
        {
            "query": "æˆ‘æƒ³å­¦ä¹ é‡‘å±ç»ç’ƒç ”ç©¶ï¼Œè¯·åˆ†æçŸ¥è¯†ç›²ç‚¹å¹¶æ¨èå­¦ä¹ èµ„æ–™",
            "expected_agent": AgentType.LEARNING_CONSULTANT,
            "description": "æµ‹è¯•å­¦ä¹ å»ºè®®åŠŸèƒ½"
        },
        {
            "query": "å¦‚ä½•ç³»ç»Ÿå­¦ä¹ åˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿæ–¹æ³•",
            "expected_agent": AgentType.LEARNING_CONSULTANT,
            "description": "æµ‹è¯•å­¦ä¹ è·¯å¾„è§„åˆ’"
        }
    ]

    print("ğŸ§ª å¼€å§‹è¿è¡Œä¸‰å¤§æ™ºèƒ½ä½“æµ‹è¯•...")
    print("=" * 60)

    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“‹ æµ‹è¯• {i}: {test_case['description']}")
        print(f"ğŸ’¬ æŸ¥è¯¢: {test_case['query']}")
        print("-" * 50)

        assigned_agent, confidence = qa_system.route_query(test_case['query'])
        print(f"ğŸ¯ åˆ†é…æ™ºèƒ½ä½“: {assigned_agent.value}")
        print(f"ğŸ“Š åˆ†é…ç½®ä¿¡åº¦: {confidence:.2f}")

        if assigned_agent == test_case['expected_agent']:
            print("âœ… æ™ºèƒ½ä½“åˆ†é…æ­£ç¡®")
        else:
            print(f"âš ï¸  æœŸæœ›: {test_case['expected_agent'].value}")

        response = qa_system.process_query(test_case['query'])
        print(f"ğŸ¤– å›ç­”é¢„è§ˆ: {response[:300]}...")

        if i < len(test_cases):
            print("\n" + "=" * 60)

    print(f"\nğŸ‰ ä¸‰å¤§æ™ºèƒ½ä½“æµ‹è¯•å®Œæˆï¼")
    print("ğŸ“ˆ ç³»ç»Ÿæ¶æ„:")
    print("  âœ… çŸ¥è¯†åº“æ£€ç´¢æ™ºèƒ½ä½“ - è®ºæ–‡ã€å†…å®¹ã€å›¾ç‰‡æ£€ç´¢")
    print("  âœ… é¢†åŸŸé¡¾é—®æ™ºèƒ½ä½“ - ç ”ç©¶åˆ†æã€æ¦‚å¿µè§£é‡Šã€æ–¹æ³•æŒ‡å¯¼ã€æ•°æ®è§£è¯»ã€æ€§èƒ½æ¯”è¾ƒ")
    print("  âœ… å­¦ä¹ é¡¾é—®æ™ºèƒ½ä½“ - çŸ¥è¯†ç›²ç‚¹åˆ†æã€å­¦ä¹ èµ„æ–™æ¨èã€å­¦ä¹ è·¯å¾„è§„åˆ’")


def pdf_agent():
    """ä¸»å‡½æ•° - å¢å¼ºç‰ˆç”¨æˆ·äº¤äº’"""
    print("ğŸ”¬ ææ–™ç§‘å­¦æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    print("=" * 60)
    print("ğŸŒŸ ä¸‰å¤§æ ¸å¿ƒæ™ºèƒ½ä½“ä¸ºæ‚¨æœåŠ¡:")
    print("")
    print("  ğŸ“š çŸ¥è¯†æ£€ç´¢ - æ‰¾è®ºæ–‡ã€æŸ¥å†…å®¹ã€æœå›¾è¡¨")
    print("  ğŸ“ é¢†åŸŸä¸“å®¶ - æ·±åº¦åˆ†æã€ä¸“ä¸šè§£é‡Šã€æ–¹æ³•æŒ‡å¯¼")
    print("  ğŸŒ å­¦ä¹ é¡¾é—® - å­¦ä¹ è§„åˆ’ã€èµ„æ–™æ¨èã€ç›²ç‚¹åˆ†æ")
    print("")
    print("ğŸ’¡ ä½¿ç”¨æç¤º:")
    print("  â€¢ è¾“å…¥ 'å¸®åŠ©' æŸ¥çœ‹ä½¿ç”¨æŒ‡å—")
    print("  â€¢ è¾“å…¥ 'æ¨¡å¼' æŸ¥çœ‹æ™ºèƒ½ä½“åŠŸèƒ½è¯´æ˜")
    print("  â€¢ è¾“å…¥ 'é€€å‡º' ç»“æŸå¯¹è¯")
    print("=" * 60)
    print("è¾“å…¥ç¤ºä¾‹ï¼šæ£€ç´¢é‡‘å±ç»ç’ƒå½¢æˆçš„ç›¸å…³è®ºæ–‡")

    # è®¾ç½®APIå¯†é’¥
    if not os.getenv("DEEPSEEK_API_KEY"):
        os.environ["DEEPSEEK_API_KEY"] = DEEPSEEK_API_KEY

    # åˆå§‹åŒ–ç³»ç»Ÿ
    qa_system = MaterialScienceQASystem()
    print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
    print("")

    conversation_history = []

    while True:
        try:
            user_input = input("ğŸ’¬ æ‚¨çš„é—®é¢˜: ").strip()

            # ç‰¹æ®Šå‘½ä»¤å¤„ç†
            if user_input.lower() in ['é€€å‡º', 'quit', 'exit', 'q']:
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼ŒæœŸå¾…å†æ¬¡ä¸ºæ‚¨æœåŠ¡ï¼")
                break

            elif user_input.lower() in ['å¸®åŠ©', 'help']:
                show_help()
                continue

            elif user_input.lower() in ['æ¨¡å¼', 'æ¨¡å¼è¯´æ˜', 'agents']:
                show_agent_modes()
                continue

            elif user_input.lower() in ['å†å²', 'history']:
                show_conversation_history(conversation_history)
                continue

            elif user_input.lower() in ['æ¸…é™¤', 'clear']:
                conversation_history.clear()
                print("ğŸ—‘ï¸  å¯¹è¯å†å²å·²æ¸…é™¤")
                continue

            if not user_input:
                print("âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆé—®é¢˜")
                continue

            print("â³ æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜...")

            # è®°å½•å¯¹è¯å†å²
            conversation_history.append({"role": "user", "content": user_input})

            # å¤„ç†æŸ¥è¯¢
            agent_type, confidence = qa_system.route_query(user_input)
            response = qa_system.process_query(user_input)

            # è®°å½•å›å¤å†å²
            conversation_history.append({"role": "assistant", "content": response, "agent": agent_type.value})

            # æ˜¾ç¤ºç»“æœ
            display_response(user_input, response, agent_type, confidence)

        except KeyboardInterrupt:
            print("\n\nğŸ›‘ å¯¹è¯ç»“æŸï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
            break
        except Exception as e:
            error_msg = f"ç³»ç»Ÿé”™è¯¯: {str(e)}"
            print(f"\nâŒ {error_msg}")
            conversation_history.append({"role": "system", "content": error_msg})


def display_response(question: str, response: str, agent_type: AgentType, confidence: float):
    """ç¾åŒ–æ˜¾ç¤ºå›å¤ç»“æœ"""
    print("\n" + "=" * 70)
    print(f"ğŸ¯ é—®é¢˜: {question}")
    print(f"ğŸ¤– å¤„ç†æ™ºèƒ½ä½“: {agent_type.value} (ç½®ä¿¡åº¦: {confidence:.2f})")
    print("=" * 70)
    print(f"\n{response}")
    print("\n" + "=" * 70)
    print("ğŸ’¡ æ‚¨å¯ä»¥ç»§ç»­æé—®ï¼Œæˆ–è¾“å…¥'å¸®åŠ©'æŸ¥çœ‹ä½¿ç”¨æŒ‡å—")
    print("")


def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    help_text = """
ğŸ“– ä½¿ç”¨æŒ‡å—:

ã€åŸºæœ¬æ“ä½œã€‘
â€¢ ç›´æ¥è¾“å…¥é—®é¢˜å³å¯è·å¾—ç­”æ¡ˆ
â€¢ è¾“å…¥ 'é€€å‡º' ç»“æŸå¯¹è¯
â€¢ è¾“å…¥ 'å†å²' æŸ¥çœ‹å¯¹è¯è®°å½•
â€¢ è¾“å…¥ 'æ¸…é™¤' æ¸…ç©ºå¯¹è¯å†å²

ã€æ™ºèƒ½ä½“åŠŸèƒ½ã€‘
â€¢ çŸ¥è¯†æ£€ç´¢: åŒ…å«"æ£€ç´¢"ã€"æœç´¢"ã€"æŸ¥æ‰¾"ç­‰å…³é”®è¯
â€¢ é¢†åŸŸä¸“å®¶: åŒ…å«"åˆ†æ"ã€"è§£é‡Š"ã€"æŒ‡å¯¼"ç­‰å…³é”®è¯  
â€¢ å­¦ä¹ é¡¾é—®: åŒ…å«"å­¦ä¹ "ã€"èµ„æ–™"ã€"ç›²ç‚¹"ç­‰å…³é”®è¯

ã€ç¤ºä¾‹é—®é¢˜ã€‘
â€¢ "æ£€ç´¢é‡‘å±ç»ç’ƒå½¢æˆçš„ç›¸å…³è®ºæ–‡"
â€¢ "è§£é‡Šä»€ä¹ˆæ˜¯å‡†æ™¶ç›¸"
â€¢ "å¦‚ä½•å­¦ä¹ åˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿ"
â€¢ "åˆ†æè®ºæ–‡çš„ç ”ç©¶ä»·å€¼"
"""
    print(help_text)


def show_agent_modes():
    """æ˜¾ç¤ºæ™ºèƒ½ä½“æ¨¡å¼è¯´æ˜"""
    modes_text = """
ğŸ¤– ä¸‰å¤§æ™ºèƒ½ä½“åŠŸèƒ½è¯¦è§£:

ğŸ“š ã€çŸ¥è¯†åº“æ£€ç´¢æ™ºèƒ½ä½“ã€‘
  æ“…é•¿: æ–‡çŒ®æ£€ç´¢ã€å†…å®¹æœç´¢ã€å›¾è¡¨æŸ¥æ‰¾
  ç¤ºä¾‹:
    â€¢ "æ£€ç´¢Ta Zré‡‘å±ç»ç’ƒçš„ç›¸å…³è®ºæ–‡"
    â€¢ "æœç´¢EAMåŠ¿å‡½æ•°æ¯”è¾ƒçš„å›¾è¡¨" 
    â€¢ "æŸ¥æ‰¾ç›¸å˜åŠ¨åŠ›å­¦çš„å…·ä½“å†…å®¹"

ğŸ“ ã€é¢†åŸŸé¡¾é—®æ™ºèƒ½ä½“ã€‘  
  æ“…é•¿: ä¸“ä¸šåˆ†æã€æ¦‚å¿µè§£é‡Šã€æ–¹æ³•æŒ‡å¯¼
  ç¤ºä¾‹:
    â€¢ "åˆ†æé‡‘å±ç»ç’ƒçš„å½¢æˆèƒ½åŠ›"
    â€¢ "è§£é‡Šæ™¶ä½“ç¼ºé™·å¯¹æ€§èƒ½çš„å½±å“"
    â€¢ "æŒ‡å¯¼åˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿæ–¹æ³•"
    â€¢ "æ¯”è¾ƒä¸åŒææ–™çš„åŠ›å­¦æ€§èƒ½"

ğŸŒ ã€å­¦ä¹ é¡¾é—®æ™ºèƒ½ä½“ã€‘
  æ“…é•¿: å­¦ä¹ è§„åˆ’ã€èµ„æ–™æ¨èã€ç›²ç‚¹åˆ†æ
  ç¤ºä¾‹:
    â€¢ "å¦‚ä½•ç³»ç»Ÿå­¦ä¹ ææ–™ç§‘å­¦"
    â€¢ "æ¨èé‡‘å±ç›¸å˜çš„å­¦ä¹ èµ„æ–™"
    â€¢ "åˆ†ææˆ‘åœ¨æ™¶ä½“å­¦æ–¹é¢çš„çŸ¥è¯†ç›²ç‚¹"
"""
    print(modes_text)


def show_conversation_history(history: list):
    """æ˜¾ç¤ºå¯¹è¯å†å²"""
    if not history:
        print("ğŸ“ å¯¹è¯å†å²ä¸ºç©º")
        return

    print("\nğŸ“ å¯¹è¯å†å²:")
    print("=" * 50)
    for i, item in enumerate(history, 1):
        if item["role"] == "user":
            print(f"ğŸ‘¤ ç¬¬{i}é—®: {item['content']}")
        elif item["role"] == "assistant":
            print(f"ğŸ¤– ç¬¬{i}ç­”: {item['content'][:100]}...")
            print(f"   æ™ºèƒ½ä½“: {item.get('agent', 'æœªçŸ¥')}")
        print("-" * 30)
    print(f"æ€»è®¡: {len([h for h in history if h['role'] == 'user'])} æ¬¡é—®ç­”")
    print("")


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "demo":
        run_three_agents_tests()
    else:
        pdf_agent()